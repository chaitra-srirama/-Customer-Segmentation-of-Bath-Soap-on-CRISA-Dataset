---
title: "clustering- Assignment 3 | IDS 572 "
author: "Chaitra Srirama, Viharika Bharti, Aditya Gajula"
date: "4/12/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r}
library(tidyverse)
library(readxl)
library(GGally)
library(plotly)
library(factoextra)
library(fpc)
library(rpart)
library(caret)
library(cluster)
library(clusterSim)
library(dbscan)
library(kernlab)

#Read the Data
bsData<- bsData<- read_excel("C:/Users/chait/Desktop/Data Mining/Assignment 3/Assgt3_BathSoap_Data.xls", sheet = "DM_Sheet")
```

#Data cleansing
```{r}
#the data read in may contain empty rows, columns, so remove these
bsData<-bsData[1:600, 1:46]

#better to change the colNames which contain punctuation, space
names(bsData) <- gsub("[[:punct:]]|\\s", "_", names(bsData))

#The data with '%' in values are read in as 'chr' type - change these to numeric
bsData[20:46]<-lapply(bsData[20:46],function(x)  as.numeric(sub("%", "e-2", x)))

bsd<- bsData

#for brLoyalty, calculate maxBr as max of purchase by different major brand (excl others)
bsd<-bsd %>% rowwise() %>%  mutate(maxBr=max(Br__Cd__57__144, Br__Cd__55, Br__Cd__272, Br__Cd__286, Br__Cd__24, Br__Cd__481, Br__Cd__352, Br__Cd__5))

```


#Converting categorical vairables to Dummy variables.
```{r}

#FEH dummy variable - DONE
summary(as.factor(bsd$FEH))
#convert this to dummies, since the values are not ordinal, and remove the '0' level dummy
bsd<-bsd %>% mutate(fehDummy=1) %>% pivot_wider(names_from = FEH, values_from = fehDummy, names_prefix = "FEH_", values_fill = list(fehDummy=0))
bsd<- bsd %>% select(-FEH_0)  # can append this to the last line too

# MT dummy variable- DONE
summary(as.factor(bsd$MT))
#keep levels 0, 4, 5, 10, 25 as dummies, with 0 in the dummies indicating 'other'
bsd<- bsd %>% mutate(MT=if_else(MT %in% c(0, 4, 5, 10, 25), MT, -1))
bsd<-bsd %>% mutate(mtDummy=1) %>% pivot_wider(names_from = MT, values_from = mtDummy, names_prefix = "MT_", values_fill = list(mtDummy=0)) 
bsd<- bsd %>% select(- `MT_-1`)

#similarly for CHILD, leave out the level '5' for unknown _ DONE
summary(as.factor(bsd$CHILD))
bsd<-bsd %>% mutate(mtChild=1) %>% pivot_wider(names_from = CHILD, values_from = mtChild, names_prefix = "CHILD_", values_fill = list(mtChild=0)) %>% select(- CHILD_5)

#CS dummies - DONE
summary(as.factor(bsd$CS))
bsd<-bsd %>% mutate(mtCS=1) %>% pivot_wider(names_from = CS, values_from = mtCS, names_prefix = "CS_", values_fill = list(mtCS=0)) %>% select(- CS_0) 

#SEX, dummies _ DONE
summary(as.factor(bsd$SEX))
bsd<-bsd %>% mutate(mtSEX=1) %>% pivot_wider(names_from = SEX, values_from = mtSEX, names_prefix = "SEX_", values_fill = list(mtSEX=0)) %>% select(- SEX_0)

#AGE- DONE
summary(as.factor(bsd$AGE))
bsd<-bsd %>% mutate(AGEDummy=1) %>% pivot_wider(names_from = AGE, values_from = AGEDummy, names_prefix = "AGE_", values_fill = list(AGEDummy=0))

#SEC - DONE
bsd<-bsd %>% mutate(SECDummy=1) %>% pivot_wider(names_from = SEC, values_from = SECDummy, names_prefix = "SEC_", values_fill = list(SECDummy=0))

#EDU- DONE
summary(as.factor(bsd$EDU))
bsd<- bsd %>% mutate(EDU=if_else(EDU %in% c(0, 4, 5, 6,7, 8, 9), EDU, -1))
bsd<-bsd %>% mutate(EDUDummy=1) %>% pivot_wider(names_from = EDU, values_from = EDUDummy, names_prefix = "EDU_", values_fill = list(EDUDummy=0)) 
bsd<- bsd %>% select(- `EDU_0`)
bsd$EDU_Schooling<-bsd$EDU_4+bsd$EDU_5
bsd$EDU_College<-bsd$EDU_6+bsd$EDU_7
bsd$EDU_Graduate_School<-bsd$EDU_8+bsd$EDU_9
bsd<- bsd %>% select(-'EDU_4', -'EDU_5', -'EDU_6', -'EDU_7', -'EDU_8', -'EDU_9')

#HS- DONE
summary(as.factor(bsd$HS))
bsd<- bsd %>% mutate(HS=if_else(HS %in% c(0,3, 4, 5,6), HS, -1))
bsd<-bsd %>% mutate(HSDummy=1) %>% pivot_wider(names_from = HS, values_from = HSDummy, names_prefix = "HS_", values_fill = list(HSDummy=0)) 
bsd<- bsd %>% select(- `HS_-1`)

```


#2a) kMeans clustering - Purchase Behavior variables
```{r}

#clustering on  purchase behavior varables
PURCHASE_BEHAVIOR <- c('No__of_Brands', 'Brand_Runs', 'Total_Volume', 'No__of__Trans', 'Value', 'Trans___Brand_Runs', 'Vol_Tran', 'Avg__Price', 'maxBr', 'Others_999')

#renaming the dataset to x
x<- bsd

# cluster function + kmeans function together in one line
kmClus_pb<- x %>% select(PURCHASE_BEHAVIOR) %>% scale() %>%kmeans(centers=3,nstart=30)

#Details:
kmClus_pb
#str(kmClus_bp)

#visualize the cluster - based on variables used for clustering
fviz_cluster(kmClus_pb, data=x %>% select(PURCHASE_BEHAVIOR))

#Create a scaled dataset 
xpb<-x %>% select(PURCHASE_BEHAVIOR) %>% scale() 

#how many clusters is best
fviz_nbclust(xpb, kmeans, method = "wss")
fviz_nbclust(xpb, kmeans, method = "silhouette")

#Interpretation

#add the cluster variable to the data and check the cluster descriptions in terms of broader set of variables
x <- x %>% mutate(clusKM=kmClus_pb$cluster)

#Interpretation
interpret <- as.data.frame(x %>% group_by(clusKM) %>% summarise_at(c('No__of_Brands', 'Brand_Runs', 'Total_Volume', 'No__of__Trans', 'Value', 'Trans___Brand_Runs', 'Vol_Tran', 'Avg__Price', 'maxBr', 'Others_999', 'SEC_1', 'SEC_2','SEC_3','SEC_4', 'EDU_-1', 'EDU_Schooling','EDU_College','EDU_Graduate_School', 'HS_4','HS_6','HS_0','HS_5','HS_3','HS_4', 'CHILD_1', 'CHILD_2', 'CHILD_3','CHILD_4', 'Affluence_Index'), mean ) %>% view())

#number of datapoints in each cluster.
table(x$clusKM)

#Interpreation- Grpah
p <- ggparcoord(data = interpret, columns = (2:29), mapping=aes(color=as.factor(clusKM)), groupColumn = "clusKM", scale = "std") + labs(x = "variable", y = "value", title = "Clustering") + scale_color_discrete("Clusters",labels=levels(interpret$clusKM)) + theme(axis.text.x = element_text(angle = 90))
ggplotly(p)


plotcluster(x, kmClus_pb$cluster)
```


#4c) #Decision tree to predict clusters 1,2,3
```{r}

set.seed(9)

#converting to factor
x$clusKM <- as.factor(x$clusKM)

#no of rows
nr<-nrow(x)

#Splitting into training and testing
trnIndex = sample(1:nr, size = round(0.7*nr), replace=FALSE) 

#training and testing
xTrn <- x[trnIndex, ] 
xTst <- x[-trnIndex, ]

library(rpart)
DTree<- rpart(clusKM ~., data=xTrn, method="class", parms = list(split = "information"), control = rpart.control(minsplit = 30, cp=0.001))

#Veiw the tree
rpart.plot::prp(DTree, type=2, extra=1)
rpart.plot::prp(DTree, box.palette="GnYlRd", shadow.col="gray", nn=TRUE)

#Confusion table for training data
predTrn=predict(DTree, xTrn, type='class')
library(caret)
CM<- confusionMatrix(predTrn, xTrn$clusKM)
CM$table

#Accuracy on training data
Accuracy <- c(round(mean(predTrn==xTrn$clusKM),2))
Accuracy

#Pruning the tree - NOTE THIS IS OPTIONAL BEACUSE THE TREE IS SOO SMALL
DTreePr<- prune.rpart(DTree, cp=0.003)

#Confusion matrix for testing data
predTst=predict(DTree, xTst, type='class')
CMTest <- confusionMatrix(predTst, xTst$clusKM)
CMTest$table

#test Accuracy
Test_Accuracy<- round(mean(predTst==xTst$clusKM),2)
Test_Accuracy

```


#2b K-means for Basis_for_purchase 
```{r}
#variables for Basis of Purchase

bsd$Pur_Promotion <- bsd$Pur_Vol_Other_Promo__ +bsd$Pur_Vol_Promo_6__

BASIS_PURCHASE <- c('Pr_Cat_1', 'Pr_Cat_2', 'Pr_Cat_3', 'Pr_Cat_4', 'Pur_Promotion', 'PropCat_5', 'PropCat_6', 'PropCat_7', 'PropCat_8')

#Rename the dataset
x1<- bsd

#build cluster
kmClus_bp<- x1 %>% select(BASIS_PURCHASE) %>% scale() %>%kmeans(centers=3, nstart=60)

#details
kmClus_bp

#visualize the cluster
fviz_cluster(kmClus_bp, data=x1 %>% select(BASIS_PURCHASE))

#scale the dataset
xbp<-x1 %>% select(BASIS_PURCHASE) %>% scale() 

#Best K value
fviz_nbclust(xbp, kmeans, method = "wss")
fviz_nbclust(xbp, kmeans, method = "silhouette")

#interpretation
x1$clusKMbp=kmClus_bp$cluster

#brand loyalty
x1<-x1 %>% rowwise() %>%  mutate(maxBr=max(Br__Cd__57__144, Br__Cd__55, Br__Cd__272, Br__Cd__286, Br__Cd__24, Br__Cd__481, Br__Cd__352, Br__Cd__5))

#interpretation
interpret2 <- as.data.frame(x1 %>% group_by(clusKMbp) %>% summarise_at(c('Pur_Vol_Other_Promo__', 'Pur_Vol_Promo_6__', 'Pur_Vol_No_Promo____', 'Pr_Cat_1', 'Pr_Cat_2', 'Pr_Cat_3','Pr_Cat_4', 'PropCat_5', 'PropCat_6', 'PropCat_7', 'PropCat_8', 'SEC_1', 'SEC_2','SEC_3','SEC_4','CS_1', 'CS_2', 'Affluence_Index'), mean, ) %>% view())

#Graph
p <- ggparcoord(data = interpret2, columns = (2:19), mapping=aes(color=as.factor(clusKMbp)), groupColumn = "clusKMbp", scale = "std") + labs(x = "variable", y = "value", title = "Clustering") + scale_color_discrete("Clusters",labels=levels(interpret2$clusKMbp)) + theme(axis.text.x = element_text(angle = 90))

ggplotly(p)
```


#2cCombined - Purchase Behavior and Basis of purchase.
```{r}
#combined Purchase Behavior and Basis of purchase variables
COMBINED <- c('No__of_Brands', 'Brand_Runs', 'Total_Volume', 'No__of__Trans', 'Value', 'Trans___Brand_Runs', 'Vol_Tran', 'Avg__Price', 'maxBr', 'Others_999', 'Pr_Cat_1', 'Pr_Cat_2', 'Pr_Cat_3', 'Pr_Cat_4', 'Pur_Promotion', 'PropCat_5', 'PropCat_6', 'PropCat_7', 'PropCat_8')

#Rename the dataset
x2<- bsd

#build cluster
kmClus_bp<- x2 %>% select(COMBINED) %>% scale() %>%kmeans(centers=2, nstart=60)

#details
kmClus_bp

#visualize the cluster
fviz_cluster(kmClus_bp, data=x2 %>% select(COMBINED))

#scale the dataset
xcomb<-x2 %>% select(COMBINED) %>% scale() 

#Best K value
fviz_nbclust(xcomb, kmeans, method = "wss")
fviz_nbclust(xcomb, kmeans, method = "silhouette")

#interpretation
x2 <- x2 %>% mutate(clusKMbp=kmClus_bp$cluster)

interpret3 <- as.data.frame(x2 %>% group_by(clusKMbp) %>% summarise_at(c('Pur_Vol_Other_Promo__', 'Pur_Vol_Promo_6__', 'Pur_Vol_No_Promo____', 'Pr_Cat_1', 'Pr_Cat_2', 'Pr_Cat_3','Pr_Cat_4', 'PropCat_5', 'PropCat_6', 'PropCat_7', 'PropCat_8', 'SEC_1', 'SEC_2','SEC_3','SEC_4','CS_1', 'CS_2', 'Affluence_Index', 'maxBr', 'EDU_Schooling','EDU_College','EDU_Graduate_School', 'HS_4','HS_6','HS_0','HS_5','HS_3'), mean, ) %>% view())

#Graph
p <- ggparcoord(data = interpret3, columns = (2:20), mapping=aes(color=as.factor(clusKMbp)), groupColumn = "clusKMbp", scale = "std") + labs(x = "variable", y = "value", title = "Clustering") + scale_color_discrete("Clusters",labels=levels(interpret3$clusKMbp)) + theme(axis.text.x = element_text(angle = 90))
ggplotly(p)

```


#Question 3

##PAM - Partitioning around mediods
```{r}

#selecting the variables for purchase behavior
PURCHASE_BEHAVIOR <- c('No__of_Brands', 'Brand_Runs', 'Total_Volume', 'No__of__Trans', 'Value', 'Trans___Brand_Runs', 'Vol_Tran', 'Avg__Price', 'maxBr', 'Others_999')

#Scaling the data based on the selected variables
xpb<-x %>% select(PURCHASE_BEHAVIOR) %>% scale() 

#Creating clusters using PAM
pam_pb<-pam(xpb, k=3, metric = "euclidean")

#details
pam_pb
pam_pb$clusinfo

#visualizing the cluster
fviz_cluster(pam_pb)

#silhoutte plot - using the silhoutte function in the cluster package
   #https://www.rdocumentation.org/packages/cluster/versions/2.1.0/topics/silhouette
si <- silhouette(pam_pb)
summary(si)
plot(si, col=1:3, border=NA)

```

#PAM based on Basis of Purchase variables:
```{r}

bsd$Pur_Promotion <- bsd$Pur_Vol_Other_Promo__ +bsd$Pur_Vol_Promo_6__

BASIS_PURCHASE <- c('Pr_Cat_1', 'Pr_Cat_2', 'Pr_Cat_3', 'Pr_Cat_4', 'Pur_Promotion', 'PropCat_5', 'PropCat_6', 'PropCat_7', 'PropCat_8')

xpb<-bsd %>% select(BASIS_PURCHASE) %>% scale() 

#Creating clusters using PAM
pam_pb<-pam(xpb, k=4, metric = "euclidean")

#details
pam_pb
pam_pb$clusinfo

#visualizing the cluster
fviz_cluster(pam_pb)

#silhoutte plot - using the silhoutte function in the cluster package
   #https://www.rdocumentation.org/packages/cluster/versions/2.1.0/topics/silhouette
si <- silhouette(pam_pb)
summary(si)
plot(si, col=1:3, border=NA)

```

#PAM combined purchase behavior and Basis of Purchase
```{r}

PURCHASE_BEHAVIOR <- c('No__of_Brands', 'Brand_Runs', 'Total_Volume', 'No__of__Trans', 'Value', 'Trans___Brand_Runs', 'Vol_Tran', 'Avg__Price', 'maxBr', 'Others_999')

BASIS_PURCHASE <- c('Pr_Cat_1', 'Pr_Cat_2', 'Pr_Cat_3', 'Pr_Cat_4', 'Pur_Promotion', 'PropCat_5', 'PropCat_6', 'PropCat_7', 'PropCat_8')


COMBINED <- c('No__of_Brands', 'Brand_Runs', 'Total_Volume', 'No__of__Trans', 'Value', 'Trans___Brand_Runs', 'Vol_Tran', 'Avg__Price', 'maxBr', 'Others_999', 'Pr_Cat_1', 'Pr_Cat_2', 'Pr_Cat_3', 'Pr_Cat_4', 'Pur_Promotion', 'PropCat_5', 'PropCat_6', 'PropCat_7', 'PropCat_8')

x_pam_com<-bsd %>% select(COMBINED) %>% scale() 

#Creating clusters using PAM
pam_pb<-pam(x_pam_com, k=4, metric = "manhattan")

#details
pam_pb
pam_pb$clusinfo

#visualizing the cluster
fviz_cluster(pam_pb)

#silhoutte plot - using the silhoutte function in the cluster package
   #https://www.rdocumentation.org/packages/cluster/versions/2.1.0/topics/silhouette
si <- silhouette(pam_pb)
summary(si)
plot(si, col=1:3, border=NA)


```


#Agnes Hierarchical clustering on Purchase of Behavior
```{r}

#selecting the variables for purchase behavior
PURCHASE_BEHAVIOR <- c('No__of_Brands', 'Brand_Runs', 'Total_Volume', 'No__of__Trans', 'Value', 'Avg__Price', 'maxBr', 'Others_999')

#Scaling the data based on the selected variables
xpb<-x %>% select(PURCHASE_BEHAVIOR) %>% scale() 

#calculating the distance using euclidean method
xdist_euc <- dist(xpb, method = "euclidean")

#using agnes from the cluster package
hierC_pb_ag_c <- agnes(xdist_euc, method = "complete" )
plot(hierC_pb_ag_c, cex=0.3, hang=-3, main="agnes-complete")

hierC_pb_ag_w <- agnes(xdist_euc, method = "ward" )
plot(hierC_pb_ag_w, cex=0.3, hang=-3, main="agnes-ward")

#check the agglomerative coeff given by agnes
hierC_pb_ag_c$ac
hierC_pb_ag_w$ac

#calculating the distance using manhattan method
xdist_manh <- dist(xpb, method = "manhattan")

#using agnes from the cluster package
hierC_pb_ag_c <- agnes(xdist_manh, method = "complete" )
plot(hierC_pb_ag_c, cex=0.3, hang=-3, main="agnes-complete")

hierC_pb_ag_w <- agnes(xdist_manh, method = "ward" )
plot(hierC_pb_ag_w, cex=0.3, hang=-3, main="agnes-ward")

#check the agglomerative coeff given by agnes
hierC_pb_ag_c$ac
hierC_pb_ag_w$ac

#calculating the distance using maximum method
xdist_max <- dist(xpb, method = "maximum")

#using agnes from the cluster package
hierC_pb_ag_c <- agnes(xdist_max, method = "complete" )
plot(hierC_pb_ag_c, cex=0.3, hang=-3, main="agnes-complete")

hierC_pb_ag_w <- agnes(xdist_max, method = "ward" )
plot(hierC_pb_ag_w, cex=0.3, hang=-3, main="agnes-ward")

#check the agglomerative coeff given by agnes
hierC_pb_ag_c$ac
hierC_pb_ag_w$ac

#use cuttree to assign different clusters to example
cut3_hierC_pb_ac_w <- cutree(hierC_pb_ag_w, k = 3)
table(cut3_hierC_pb_ac_w)
fviz_cluster(list(data=xpb,cluster=cut3_hierC_pb_ac_c ), main="agnes-complete")

#dendograms using fviz_dend
fviz_dend(hierC_pb_ag_w)

fviz_dend(hierC_pb_ag_w, k=3, color_labels_by_k = FALSE, rect=TRUE, main="agnes - Wards")

#circular dendogram 
fviz_dend(hierC_pb_ag_w, k=3, color_labels_by_k = TRUE, type="circular", rect=TRUE, main="agnes - Wards")



```

#Agnes Hierarchical clustering on Basis of Purchase
```{r}
#selecting the variables for basis for purchase
BASIS_OF_PURCHASE <- c('Pr_Cat_1', 'Pr_Cat_2', 'Pr_Cat_3' ,'Pr_Cat_4', 'pur_promotion', 'PropCat_5', 'PropCat_6', 'PropCat_7', 'PropCat_8')

#Scaling the data based on the selected variables
ybp<-y %>% select(BASIS_OF_PURCHASE) %>% scale() 

#calculating the distance using euclidean method
xdist_euc <- dist(ybp, method = "euclidean")

#using agnes from the cluster package
hierC_pb_ag_c <- agnes(xdist_euc, method = "complete" )
plot(hierC_pb_ag_c, cex=0.3, hang=-3, main="agnes-complete")

hierC_pb_ag_w <- agnes(xdist_euc, method = "ward" )
plot(hierC_pb_ag_w, cex=0.3, hang=-3, main="agnes-ward")

#check the agglomerative coeff given by agnes
hierC_pb_ag_c$ac
hierC_pb_ag_w$ac

#calculating the distance using manhattan method
xdist_manh <- dist(ybp, method = "manhattan")

#using agnes from the cluster package
hierC_pb_ag_c <- agnes(xdist_manh, method = "complete" )
plot(hierC_pb_ag_c, cex=0.3, hang=-3, main="agnes-complete")

hierC_pb_ag_w <- agnes(xdist_manh, method = "ward" )
plot(hierC_pb_ag_w, cex=0.3, hang=-3, main="agnes-ward")

#check the agglomerative coeff given by agnes
hierC_pb_ag_c$ac
hierC_pb_ag_w$ac

#calculating the distance using maximum method
xdist_max <- dist(ybp, method = "maximum")

#using agnes from the cluster package
hierC_pb_ag_c <- agnes(xdist_max, method = "complete" )
plot(hierC_pb_ag_c, cex=0.3, hang=-3, main="agnes-complete")

hierC_pb_ag_w <- agnes(xdist_max, method = "ward" )
plot(hierC_pb_ag_w, cex=0.3, hang=-3, main="agnes-ward")

#check the agglomerative coeff given by agnes
hierC_pb_ag_c$ac
hierC_pb_ag_w$ac


#use cuttree to assign different clusters to example
cut3_hierC_pb_ac_w <- cutree(hierC_pb_ag_w, k = 3)
table(cut3_hierC_pb_ac_w)
fviz_cluster(list(data=ybp,cluster=cut3_hierC_pb_ac_c ), main="agnes-complete")

#dendograms using fviz_dend
fviz_dend(hierC_pb_ag_w)

fviz_dend(hierC_pb_ag_w, k=3, color_labels_by_k = FALSE, rect=TRUE, main="agnes - Wards")

#circular dendogram 
fviz_dend(hierC_pb_ag_w, k=3, color_labels_by_k = TRUE, type="circular", rect=TRUE, main="agnes - Wards")

```

# agnes for combined variables
```{r}
#selecting the variables for basis for purchase
COMBINED <- c('No__of_Brands', 'Brand_Runs', 'Total_Volume', 'No__of__Trans', 'Value', 'Trans___Brand_Runs', 'Vol_Tran', 'Avg__Price', 'maxBr', 'Others_999', 'Pr_Cat_1', 'Pr_Cat_2', 'Pr_Cat_3', 'Pr_Cat_4', 'Pur_Promotion', 'PropCat_5', 'PropCat_6', 'PropCat_7', 'PropCat_8')

#Scaling the data based on the selected variables
pbbp<-z %>% select(COMBINED) %>% scale() 

#calculating the distance using euclidean method
xdist_euc <- dist(pbbp, method = "euclidean")

#using agnes from the cluster package
hierC_pb_ag_c <- agnes(xdist_euc, method = "complete" )
plot(hierC_pb_ag_c, cex=0.3, hang=-3, main="agnes-complete")

hierC_pb_ag_w <- agnes(xdist_euc, method = "ward" )
plot(hierC_pb_ag_w, cex=0.3, hang=-3, main="agnes-ward")

#check the agglomerative coeff given by agnes
hierC_pb_ag_c$ac
hierC_pb_ag_w$ac

#calculating the distance using manhattan method
xdist_manh <- dist(pbbp, method = "manhattan")

#using agnes from the cluster package
hierC_pb_ag_c <- agnes(xdist_manh, method = "complete" )
plot(hierC_pb_ag_c, cex=0.3, hang=-3, main="agnes-complete")

hierC_pb_ag_w <- agnes(xdist_manh, method = "ward" )
plot(hierC_pb_ag_w, cex=0.3, hang=-3, main="agnes-ward")

#check the agglomerative coeff given by agnes
hierC_pb_ag_c$ac
hierC_pb_ag_w$ac

#calculating the distance using maximum method
xdist_max <- dist(pbbp, method = "maximum")

#using agnes from the cluster package
hierC_pb_ag_c <- agnes(xdist_max, method = "complete" )
plot(hierC_pb_ag_c, cex=0.3, hang=-3, main="agnes-complete")

hierC_pb_ag_w <- agnes(xdist_max, method = "ward" )
plot(hierC_pb_ag_w, cex=0.3, hang=-3, main="agnes-ward")

#check the agglomerative coeff given by agnes
hierC_pb_ag_c$ac
hierC_pb_ag_w$ac


#use cuttree to assign different clusters to example
cut3_hierC_pb_ac_w <- cutree(hierC_pb_ag_w, k = 3)
table(cut3_hierC_pb_ac_w)
fviz_cluster(list(data=pbbp,cluster=cut3_hierC_pb_ac_c ), main="agnes-complete")

#dendograms using fviz_dend
fviz_dend(hierC_pb_ag_w)

fviz_dend(hierC_pb_ag_w, k=3, color_labels_by_k = FALSE, rect=TRUE, main="agnes - Wards")

#circular dendogram 
fviz_dend(hierC_pb_ag_w, k=3, color_labels_by_k = TRUE, type="circular", rect=TRUE, main="agnes - Wards")
```
#DBSCAN clustering - example using the 'multishapes' dataset in the 'factoextra' package
```{r}

data("multishapes")

#Plot the points
multishapes %>% ggplot(aes(x=x,y=y, col=as.factor(shape)))+geom_point()
 
msKMeans <- kmeans(multishapes[,1:2], 5, nstart = 25)

fviz_cluster(msKMeans, data = multishapes[,1:2], main="kMeans on multishapes")


#Now use dbscan 

#dbscan - https://www.rdocumentation.org/packages/dbscan/versions/1.1-5/topics/dbscan

msDbscan <- dbscan(multishapes[,1:2], eps = 0.5, minPts = 5)

fviz_cluster(msDbscan, data=multishapes[,1:2], geom="point", ellipse  = FALSE, main="dbscan eps=0.5, minPts=5")

#optimal eps value
kNNdistplot(multishapes[,1:2], k=4)

    #https://www.rdocumentation.org/packages/dbscan/versions/1.1-5/topics/kNNdist

```


# Kernel k-means for purchase of behavior
```{r}

  #kkmeans - https://www.rdocumentation.org/packages/kernlab/versions/0.9-29/topics/kkmeans

kkc_pb<-kkmeans( xpb,centers=3)
     #uses default values - rbf kernal, and automatically sets the kernel
kkc_pb

#the cluster assignments for examples is in kkc_pb@.Data - use this for vizualizing using fviz_cluster

fviz_cluster(list(data=xpb, cluster=kkc_pb@.Data), geom="points", main="kkmeans")


#polynomial kernel with degree 2
kkc_pb_p2<-kkmeans( xpb,centers=3, kernel='polydot', kpar=list(degree=2))

#rbf kernel with specified sigma parameter
kkc_pb_rbf<-kkmeans( xpb,centers=3, kernel='rbfdot', kpar=list(sigma=0.2 ))

```

# Kernel k-means for basis of purchase
```{r}
kkc_bp<-kkmeans( ybp,centers=3)
     #uses default values - rbf kernal, and automatically sets the kernel
kkc_bp

#the cluster assignments for examples is in kkc_pb@.Data - use this for vizualizing using fviz_cluster

fviz_cluster(list(data=ybp, cluster=kkc_bp@.Data), geom="points", main="kkmeans")


#polynomial kernel with degree 2
kkc_bp_p2<-kkmeans( ybp,centers=3, kernel='polydot', kpar=list(degree=2))

#rbf kernel with specified sigma parameter
kkc_bp_rbf<-kkmeans( ybp,centers=3, kernel='rbfdot', kpar=list(sigma=0.2 ))
```

# Kernel k-means for combined variable
```{r}
kkc_c<-kkmeans( pbbp,centers=3)
     #uses default values - rbf kernal, and automatically sets the kernel
kkc_c

#the cluster assignments for examples is in kkc_pb@.Data - use this for vizualizing using fviz_cluster

fviz_cluster(list(data=pbbp, cluster=kkc_c@.Data), geom="points", main="kkmeans")


#polynomial kernel with degree 2
kkc_c_p2<-kkmeans( pbbp,centers=3, kernel='polydot', kpar=list(degree=2))

#rbf kernel with specified sigma parameter
kkc_c_rbf<-kkmeans( pbbp,centers=3, kernel='rbfdot', kpar=list(sigma=0.2 ))
```


#Question 4c -> Decision tree to interpret clusters performed on K-means - purchase variables see Line 155 for code. 

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
